{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counting corners in polygons\n",
    "\n",
    "In this optional exercise you will: \n",
    "\n",
    "* Train a CNN to count corners in polygons\n",
    "\n",
    "## The data\n",
    "\n",
    "The images are almost black and white images of polygons, from triangles up to polygons with 10 corners.\n",
    "The task is simply to be able to predict the number of corners given an input image. The size of the \n",
    "images are 100x100. There is a training dataset of 5000 images and a testset of also 5000 images. There is also\n",
    "a dataset where training data only contain odd number of corners and testdata only even number of corners.\n",
    "\n",
    "## The exercises\n",
    "See cell # below.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CellName: Init (#1)\n",
    "### CellType: Needed\n",
    "### Cell instruction: Initializing the libraries\n",
    "In the cell below, we import all the libraries that are needed for this exercises. There is one configuration parameter that you can change in this cell\n",
    "\n",
    "* Inline or \"pop out\" plots.\n",
    "\n",
    "See comments in the cell for more information. Run the cell by entering into the cell and press \"CTRL Enter\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 11567575051210126702\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# These two lines is just to avoid some warnings, coming from the fact that we are running\n",
    "# tensorflow 1.14 and not the latest version.\n",
    "from warnings import simplefilter\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"\"\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Input, Activation\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "from tensorflow.keras.layers import Lambda, concatenate\n",
    "from tensorflow.keras.layers import LSTM, GRU, SimpleRNN, RNN\n",
    "\n",
    "from tensorflow.keras.optimizers import SGD, Adam, RMSprop, Nadam\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from sklearn.metrics import *\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "# To have the plots inside the notebook \"inlin\" should be True. \n",
    "# If \"inlin\" = False, then plots will pop out of the notebook\n",
    "inlin = True # True/False\n",
    "if inlin:\n",
    "    %matplotlib inline\n",
    "else:\n",
    "    %matplotlib\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CellName: Data (#2)\n",
    "### CellType: Needed\n",
    "### Cell instruction: Function for loading the polygons\n",
    "\n",
    "Run the cell by entering into the cell and press \"CTRL Enter\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadImages(folder,trgFile,n):\n",
    "    import imageio\n",
    "    def load_pics(folder,n):\n",
    "        imgs = []\n",
    "        for i in range(n):\n",
    "            img = imageio.imread(folder+\"img_{:05}.png\".format(i+1))\n",
    "            ch = img[:,:,0]\n",
    "            imgs.append(ch)\n",
    "        return np.array(imgs)\n",
    "\n",
    "    def load_labels(fn):\n",
    "        return np.loadtxt(fn, usecols=0)\n",
    "\n",
    "    pic = load_pics(folder+\"/\", n)\n",
    "    ndata, width, height = pic.shape\n",
    "\n",
    "    inp = (pic/np.float32(255)).reshape(n, width, height, 1)\n",
    "    trg = load_labels(trgFile)\n",
    "    trg = trg[0:n]\n",
    "\n",
    "    return inp, trg, width, height\n",
    "\n",
    "def loadDataAll(nTrn, nTst):\n",
    "    # Load data\n",
    "    (trnInp, trnTrg, imgW, imgH) = loadImages(\"polyAll-trn\", \"polyAll-trn_trg.csv\", nTrn)\n",
    "    (tstInp, tstTrg, imgW, imgH) = loadImages(\"polyAll-tst\", \"polyAll-tst_trg.csv\", nTst)\n",
    "\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        trnInp = trnInp.reshape(trnInp.shape[0], 1, imgH, imgW)\n",
    "        tstInp = tstInp.reshape(tstInp.shape[0], 1, imgH, imgW)\n",
    "        input_shape = (1, imgH, imgW)\n",
    "    else:\n",
    "        trnInp = trnInp.reshape(trnInp.shape[0], imgH, imgW, 1)\n",
    "        tstInp = tstInp.reshape(tstInp.shape[0], imgH, imgW, 1)\n",
    "        input_shape = (imgH, imgW, 1)\n",
    "\n",
    "    print('trnInp shape:', trnInp.shape)\n",
    "    print('tstInp shape:', tstInp.shape)\n",
    "\n",
    "    return trnInp, trnTrg, tstInp, tstTrg, input_shape\n",
    "\n",
    "def loadDataOddEven(nTrn, nTst):\n",
    "    # Load data\n",
    "    (trnInp, trnTrg, imgW, imgH) = loadImages(\"polyOdd-trn\", \"polyOdd-trn_trg.csv\", nTrn)\n",
    "    (tstInp, tstTrg, imgW, imgH) = loadImages(\"polyEven-tst\", \"polyEven-tst_trg.csv\", nTst)\n",
    "\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        trnInp = trnInp.reshape(trnInp.shape[0], 1, imgH, imgW)\n",
    "        tstInp = tstInp.reshape(tstInp.shape[0], 1, imgH, imgW)\n",
    "        input_shape = (1, imgH, imgW)\n",
    "    else:\n",
    "        trnInp = trnInp.reshape(trnInp.shape[0], imgH, imgW, 1)\n",
    "        tstInp = tstInp.reshape(tstInp.shape[0], imgH, imgW, 1)\n",
    "        input_shape = (imgH, imgW, 1)\n",
    "\n",
    "    print('trnInp shape:', trnInp.shape)\n",
    "    print('tstInp shape:', tstInp.shape)\n",
    "\n",
    "    return trnInp, trnTrg, tstInp, tstTrg, input_shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CellName: PlotImg (#3)\n",
    "### CellType: Information\n",
    "### Cell instruction: Show some of the images\n",
    "\n",
    "Here we look at the first ten pictures in the training set, and their respective targets. \n",
    "\n",
    "Run the cell by entering into the cell and press \"CTRL Enter\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trnInp shape: (10, 100, 100, 1)\n",
      "tstInp shape: (10, 100, 100, 1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets:\n",
      "[ 3. 10.  5.  3.  3.  9.  9.  6. 10.  7.]\n"
     ]
    }
   ],
   "source": [
    "trnInp, trnTrg, tstInp, tstTrg, input_shape = loadDataAll(10,10)\n",
    "#trnInp, trnTrg, tstInp, tstTrg, input_shape = loadDataOddEven(10,10)\n",
    "\n",
    "plt.figure(1, figsize=(15,10))\n",
    "plt.imshow(trnInp[:10,:,:].swapaxes(0,1).reshape(input_shape[1],10*input_shape[1]),cmap=\"gray\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Targets:\")\n",
    "print(trnTrg[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CellName: Stats (#4)\n",
    "### CellType: Needed\n",
    "### Cell instruction: Plot a confusion matrix\n",
    "\n",
    "Run the cell by entering into the cell and press \"CTRL Enter\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm,\n",
    "                          target_names,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=None,\n",
    "                          normalize=True):\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    import itertools\n",
    "\n",
    "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "    misclass = 1 - accuracy\n",
    "\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    plt.ylim([-0.5, cm.shape[0]-0.5])\n",
    "\n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names, rotation=45)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CellName: Ex1 (#5)\n",
    "### CellType: Exercise\n",
    "### Cell instruction: Instructions for question 1-2\n",
    "\n",
    "## CNN for counting corners\n",
    "\n",
    "#### Question 1\n",
    "The question is simple! **Find a CNN model that can accurately counts the corners in the test data set.**\n",
    "You have access to 5000 training images, but you may have to reduce that to be able to run it on your computer. In the\n",
    "example code below I use 1000 training images.\n",
    "\n",
    "**Hint 1** The cell below contains my simple model that is not so accurate. You can use the code as a starting point.\n",
    "**Hint 2** How can we count corners? My suggestion is to solve this using a regression approach. The CNN will try\n",
    "to predict the number of corners. So my output is a single linear node and I use MSE as a loss function. You can of\n",
    "course also try to solve it using a classification approach, but then you will a problem, extrapolating to other\n",
    "number of corners.\n",
    "**Hint 3** The target data for the images are the number of corners. I rescale this by 10 before training.\n",
    "**Hint 4** Cells #6 and #7 contains some code for visualizing the results of your model.\n",
    "\n",
    "#### Question 2\n",
    "There is a function \"loadDataOddEven\" that loads a training dataset with only odd number of corners and a test\n",
    "dataset with only even number of corners. **Try to \"solve\" this problem with a CNN!**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trnInp shape: (1000, 100, 100, 1)\n",
      "tstInp shape: (5000, 100, 100, 1)\n",
      "{3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0}\n",
      "Data loaded.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Get the training data\n",
    "(trnInp, trnTrg, tstInp, tstTrg, input_shape) = loadDataAll(1000,5000)\n",
    "print(set(trnTrg.ravel()))\n",
    "trnTrg /= 10;\n",
    "tstTrg /= 10;\n",
    "#trnTrg = to_categorical(trnTrg)\n",
    "#tstTrg = to_categorical(tstTrg)\n",
    "\n",
    "print(\"Data loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('database or disk is full')).History will not be written to the database.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "model_41 (Model)             (None, 48)                35776     \n",
      "_________________________________________________________________\n",
      "dense_80 (Dense)             (None, 10)                490       \n",
      "_________________________________________________________________\n",
      "dense_81 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 36,277\n",
      "Trainable params: 36,277\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model created.\n",
      "Train on 1000 samples, validate on 5000 samples\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 276s 276ms/sample - loss: 0.0627 - mean_absolute_error: 0.1926 - val_loss: 0.0270 - val_mean_absolute_error: 0.1373\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 312s 312ms/sample - loss: 0.0305 - mean_absolute_error: 0.1416 - val_loss: 0.0234 - val_mean_absolute_error: 0.1251\n",
      "Epoch 3/20\n",
      " 224/1000 [=====>........................] - ETA: 2:02 - loss: 0.0287 - mean_absolute_error: 0.1402"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Concatenate, AveragePooling2D, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import SGD, RMSprop\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "import math\n",
    "\n",
    "batch_size = 16\n",
    "num_output = 1\n",
    "epochs = 20\n",
    "\n",
    "inputs = Input(input_shape)\n",
    "\n",
    "# Convolutional base 1\n",
    "x = Conv2D(16, (3, 3), padding=\"same\", activation=\"relu\")(inputs)\n",
    "x = AveragePooling2D((2, 2))(x)\n",
    "x = Conv2D(16, (3, 3), padding=\"same\", activation=\"relu\")(x)\n",
    "x = AveragePooling2D((2, 2))(x)\n",
    "x = Conv2D(16, (3, 3), padding=\"same\", activation=\"relu\")(x)\n",
    "in_1 = GlobalAveragePooling2D()(x)\n",
    "\n",
    "# Convolutional base 2\n",
    "x = Conv2D(16, (5, 5), padding=\"same\", activation=\"relu\")(inputs)\n",
    "x = AveragePooling2D((2, 2))(x)\n",
    "x = Conv2D(16, (5, 5), padding=\"same\", activation=\"relu\")(x)\n",
    "x = AveragePooling2D((2, 2))(x)\n",
    "x = Conv2D(16, (5, 5), padding=\"same\", activation=\"relu\")(x)\n",
    "in_2 = GlobalAveragePooling2D()(x)\n",
    "\n",
    "# Convolutional base 3\n",
    "x = Conv2D(8, (7, 7), padding=\"same\", activation=\"relu\")(inputs)\n",
    "x = AveragePooling2D((2, 2))(x)\n",
    "x = Conv2D(8, (7, 7), padding=\"same\", activation=\"relu\")(x)\n",
    "x = AveragePooling2D((2, 2))(x)\n",
    "x = Conv2D(8, (7, 7), padding=\"same\", activation=\"relu\")(x)\n",
    "in_3 = GlobalAveragePooling2D()(x)\n",
    "\n",
    "# Convolutional base 4\n",
    "x = Conv2D(8, (9, 9), padding=\"same\", activation=\"relu\")(inputs)\n",
    "x = AveragePooling2D((2, 2))(x)\n",
    "x = Conv2D(8, (9, 9), padding=\"same\", activation=\"relu\")(x)\n",
    "x = AveragePooling2D((2, 2))(x)\n",
    "x = Conv2D(8, (9, 9), padding=\"same\", activation=\"relu\")(x)\n",
    "in_4 = GlobalAveragePooling2D()(x)\n",
    "\n",
    "outputs = Concatenate()([in_1, in_2, in_3, in_4])\n",
    "\n",
    "conv_base = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(conv_base)\n",
    "\n",
    "# The dense layers\n",
    "#model.add(Flatten()) # Not needed if using GlobalAveragePooling\n",
    "model.add(Dense(10, activation='relu'))\n",
    "#model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(num_output, activation='linear'))\n",
    "    \n",
    "model.compile(loss='mean_squared_error',\n",
    "              #optimizer=Adam(lr=0.0001),\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['mae'])\n",
    "model.summary()\n",
    "print(\"Model created.\")\n",
    "\n",
    "estimator = model.fit(trnInp, trnTrg,\n",
    "            batch_size=batch_size,\n",
    "            epochs=epochs,\n",
    "            verbose=1,\n",
    "            validation_data=(tstInp, tstTrg))\n",
    "\n",
    "trnSc = model.evaluate(trnInp, trnTrg, verbose=0)\n",
    "tstSc = model.evaluate(tstInp, tstTrg, verbose=0)\n",
    "print('Trn loss:', trnSc[0])\n",
    "print('Tst loss:', tstSc[0])\n",
    "\n",
    "# Plot the learning curves\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(estimator.history['loss'], label='Training')\n",
    "plt.plot(estimator.history['val_loss'], label='Validation')\n",
    "plt.ylabel('MAE')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CellName: Scatterplot (#6)\n",
    "### CellType: Exercise\n",
    "### Cell instruction: Make a scatter plot\n",
    "\n",
    "This cell just makes two scatter plots between the predicted output and the target output, for both\n",
    "training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plots of predicted and true values\n",
    "trnPred = model.predict(trnInp)*10\n",
    "tstPred = model.predict(tstInp)*10\n",
    "trnTr = trnTrg*10\n",
    "tstTr = tstTrg*10\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(trnPred[:], trnTr[:], 'g.', label='Predict vs True (Training)')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(tstPred[:], tstTr[:], 'g.', label='Predict vs True (Test)')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CellName: Confusion (#7)\n",
    "### CellType: Exercise\n",
    "### Cell instruction: Plot confusion matrix\n",
    "\n",
    "This cell just plots the confusion matrices for both training and testdata. In order to make a \"prediction\" of the number of corners, the output from the CNN model is rounded to nearest integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Scatter plots of predicted and true values\n",
    "trnPred = model.predict(trnInp)*10\n",
    "tstPred = model.predict(tstInp)*10\n",
    "trnTr = trnTrg*10\n",
    "tstTr = tstTrg*10\n",
    "\n",
    "nTrn = trnInp.shape[0]\n",
    "nTst = tstInp.shape[0]\n",
    "\n",
    "trnClPred = np.rint(trnPred).reshape(nTrn)\n",
    "trnClPred = trnClPred.astype(int)\n",
    "trnClTrg = np.rint(trnTr).astype(int)\n",
    "\n",
    "tstClPred = np.rint(tstPred).reshape(nTst)\n",
    "tstClPred = tstClPred.astype(int)\n",
    "tstClTrg = np.rint(tstTr).astype(int)\n",
    "\n",
    "minTrn = min(min(trnClTrg), min(trnClPred))\n",
    "maxTrn = max(max(trnClTrg), max(trnClPred))\n",
    "trgName = [];\n",
    "for x in range(minTrn, maxTrn+1):\n",
    "    trgName.append(str(x))\n",
    "\n",
    "minTst = min(min(tstClTrg), min(tstClPred))\n",
    "maxTst = max(max(tstClTrg), max(tstClPred))\n",
    "tstName = [];\n",
    "for x in range(minTst, maxTst+1):\n",
    "    tstName.append(str(x))\n",
    "    \n",
    "confuTrn = confusion_matrix(trnClTrg, trnClPred)\n",
    "confuTst = confusion_matrix(tstClTrg, tstClPred)\n",
    "\n",
    "plot_confusion_matrix(cm           = confuTrn, \n",
    "                      normalize    = False,\n",
    "                      target_names = trgName,\n",
    "                      title        = \"Confusion Matrix: Training\")\n",
    "\n",
    "plot_confusion_matrix(cm           = confuTst, \n",
    "                      normalize    = False,\n",
    "                      target_names = tstName,\n",
    "                      title        = \"Confusion Matrix: Test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy 0.2376"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I presume that, all the different types of corners require different sizes of kernels for extraction. \n",
    "# Therefore, I parallelize many convolutional bases where the first layer has different kernel sizes.\n",
    "\n",
    "# The fully-connected layer is kept as small as possible, because we don't need any non-linear mapping.\n",
    "# Mainly because the target value is \"invariant to transposes\". We are only counting the number of corners.\n",
    "# Therefore, the focus is to train a good convolution base layer.\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Get the training data\n",
    "(trnInp, trnTrg, tstInp, tstTrg, input_shape) = loadDataOddEven(1000,5000)\n",
    "print(set(trnTrg.ravel()))\n",
    "trnTrg /= 10;\n",
    "tstTrg /= 10;\n",
    "#trnTrg = to_categorical(trnTrg)\n",
    "#tstTrg = to_categorical(tstTrg)\n",
    "\n",
    "print(\"Data loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "num_output = 1\n",
    "epochs = 40\n",
    "\n",
    "inputs = Input(input_shape)\n",
    "\n",
    "# Convolutional base 1\n",
    "x = Conv2D(16, (3, 3), padding=\"same\", activation=\"relu\")(inputs)\n",
    "x = AveragePooling2D((4, 4))(x)\n",
    "x = Conv2D(16, (3, 3), padding=\"same\", activation=\"relu\")(x)\n",
    "x = AveragePooling2D((4, 4))(x)\n",
    "x = Conv2D(16, (3, 3), padding=\"same\", activation=\"relu\")(x)\n",
    "in_1 = AveragePooling2D((4, 4))(x)\n",
    "\n",
    "# Convolutional base 2\n",
    "x = Conv2D(16, (5, 5), padding=\"same\", activation=\"relu\")(inputs)\n",
    "x = AveragePooling2D((4, 4))(x)\n",
    "x = Conv2D(16, (5, 5), padding=\"same\", activation=\"relu\")(x)\n",
    "x = AveragePooling2D((4, 4))(x)\n",
    "x = Conv2D(16, (5, 5), padding=\"same\", activation=\"relu\")(x)\n",
    "in_2 = AveragePooling2D((4, 4))(x)\n",
    "\n",
    "# Convolutional base 3\n",
    "x = Conv2D(8, (7, 7), padding=\"same\", activation=\"relu\")(inputs)\n",
    "x = AveragePooling2D((4, 4))(x)\n",
    "x = Conv2D(8, (7, 7), padding=\"same\", activation=\"relu\")(x)\n",
    "x = AveragePooling2D((4, 4))(x)\n",
    "x = Conv2D(8, (7, 7), padding=\"same\", activation=\"relu\")(x)\n",
    "in_3 = AveragePooling2D((4, 4))(x)\n",
    "\n",
    "# Convolutional base 4\n",
    "x = Conv2D(8, (9, 9), padding=\"same\", activation=\"relu\")(inputs)\n",
    "x = AveragePooling2D((4, 4))(x)\n",
    "x = Conv2D(8, (9, 9), padding=\"same\", activation=\"relu\")(x)\n",
    "x = AveragePooling2D((4, 4))(x)\n",
    "x = Conv2D(8, (9, 9), padding=\"same\", activation=\"relu\")(x)\n",
    "in_4 = AveragePooling2D((4, 4))(x)\n",
    "\n",
    "outputs = Concatenate()([in_1, in_2, in_3, in_4])\n",
    "\n",
    "conv_base = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(conv_base)\n",
    "\n",
    "# The dense layers\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10, activation='relu'))\n",
    "#model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(num_output, activation='linear'))\n",
    "    \n",
    "model.compile(loss='mean_squared_error',\n",
    "              #optimizer=Adam(lr=0.0001),\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['mae'])\n",
    "model.summary()\n",
    "print(\"Model created.\")\n",
    "\n",
    "estimator = model.fit(trnInp, trnTrg,\n",
    "            batch_size=batch_size,\n",
    "            epochs=epochs,\n",
    "            verbose=1,\n",
    "            validation_data=(tstInp, tstTrg))\n",
    "\n",
    "trnSc = model.evaluate(trnInp, trnTrg, verbose=0)\n",
    "tstSc = model.evaluate(tstInp, tstTrg, verbose=0)\n",
    "print('Trn loss:', trnSc[0])\n",
    "print('Tst loss:', tstSc[0])\n",
    "\n",
    "# Plot the learning curves\n",
    "plt.figure()\n",
    "plt.plot(estimator.history['loss'], label='Training')\n",
    "plt.plot(estimator.history['val_loss'], label='Validation')\n",
    "plt.ylabel('MAE')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
